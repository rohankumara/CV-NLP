{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 15s 245us/sample - loss: 0.4726\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 14s 237us/sample - loss: 0.3568\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.3213\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.2970\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.2790\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 0.3469\n",
      "[1.2444933e-06 2.0456074e-10 2.4111892e-09 4.0810790e-09 5.0166857e-08\n",
      " 7.3372414e-03 1.9142362e-07 7.0981234e-02 1.1898426e-06 9.2167878e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.5220\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.3998\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3602\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3357\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.317 - 2s 35us/sample - loss: 0.3184\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.3689\n",
      "[2.4382229e-05 1.2963314e-09 5.2871940e-07 1.1364853e-06 1.6687735e-06\n",
      " 3.0183906e-02 4.3680425e-06 1.3607994e-01 1.3356034e-04 8.3357054e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
    "#model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.5213\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3934\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3562\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3289\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3120\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.3574\n",
      "[3.5295971e-06 2.7856257e-09 2.6395114e-07 1.1529791e-08 1.7012308e-06\n",
      " 1.1232877e-01 1.8713719e-06 1.2236964e-01 9.5681833e-05 7.6519853e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# Replace the above model definiton with this one to see the network with 5 output layers\n",
    "# And you'll see errors as a result!\n",
    "# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "#                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.5225\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3911\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3540\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.33140s -\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3137\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.4056\n",
      "[2.8778140e-07 3.1692047e-09 7.7734177e-07 2.6048185e-06 3.6204522e-08\n",
      " 6.4585912e-03 1.5862431e-06 3.8659875e-03 2.5453068e-05 9.8964465e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# Replace the above model definiton with this one to see the network with 5 output layers\n",
    "# And you'll see errors as a result!\n",
    "# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "#                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.4709\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3542\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3186\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2939\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2784\n",
      "10000/10000 [==============================] - 0s 41us/sample - loss: 0.3495\n",
      "[5.7940777e-09 3.3396336e-08 4.0334776e-09 1.3444341e-09 9.6581640e-09\n",
      " 1.2402069e-03 1.9540044e-08 5.2564098e-03 3.3648652e-07 9.9350303e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.4952\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3735\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.3358\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.3127\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2963\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2808\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2665\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2568\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2458\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2395\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2294\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2219\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2156\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2074\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2026\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1958\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.1911\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1879\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.1815\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1782\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1735\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1698\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1642\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.1616\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1586\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1533\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1517\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.1485\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.1440\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1412\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.3993\n",
      "[4.3459887e-23 1.5475377e-29 2.4980998e-24 2.3913960e-27 3.5353375e-17\n",
      " 2.4601341e-21 5.6282480e-23 1.8845142e-24 1.0000000e+00 1.5036441e-35]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[34])\n",
    "print(test_labels[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
